{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the seed for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:53:49.583915500Z",
     "start_time": "2024-07-09T14:53:46.756490600Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "\n",
    "setup_seed(3407)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definet the device used for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:53:53.198892200Z",
     "start_time": "2024-07-09T14:53:53.115103600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "gpu_list = [0]\n",
    "gpu_list_str = ','.join(map(str, gpu_list))\n",
    "os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", gpu_list_str)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the `Hist2Cell` model, and load the model on GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:53:58.804910300Z",
     "start_time": "2024-07-09T14:53:54.216629900Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch_geometric.nn import GATv2Conv, LayerNorm\n",
    "import sys,os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from model.ViT import Mlp, VisionTransformer\n",
    "\n",
    "class Hist2Cell(nn.Module):\n",
    "    def __init__(self, cell_dim=80, vit_depth=3):\n",
    "        super(Hist2Cell, self).__init__()\n",
    "        self.resnet18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.resnet18 = torch.nn.Sequential(*list(self.resnet18.children())[:-1])\n",
    "        \n",
    "        self.embed_dim = 32 * 8\n",
    "        self.head = 8\n",
    "        self.dropout = 0.3\n",
    "        \n",
    "        self.conv1 = GATv2Conv(in_channels=512, out_channels=int(self.embed_dim/self.head), heads=self.head)\n",
    "        self.norm1 = LayerNorm(in_channels=self.embed_dim)\n",
    "        \n",
    "        self.cell_transformer = VisionTransformer(num_classes=cell_dim, embed_dim=self.embed_dim, depth=vit_depth,\n",
    "                                                  mlp_head=True, drop_rate=self.dropout, attn_drop_rate=self.dropout)\n",
    "        self.spot_fc = Linear(in_features=512, out_features=256)\n",
    "        self.spot_head = Mlp(in_features=256, hidden_features=512*2, out_features=cell_dim)\n",
    "        self.local_head = Mlp(in_features=256, hidden_features=512*2, out_features=cell_dim)\n",
    "        self.fused_head = Mlp(in_features=256, hidden_features=512*2, out_features=cell_dim)\n",
    "    \n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x_spot = self.resnet18(x)\n",
    "        x_spot = x_spot.squeeze()\n",
    "        \n",
    "        x_local = self.conv1(x=x_spot, edge_index=edge_index)\n",
    "        x_local = self.norm1(x_local)\n",
    "        \n",
    "        x_local = x_local.unsqueeze(0)\n",
    "        \n",
    "        x_cell = x_local\n",
    "        \n",
    "        x_spot = self.spot_fc(x_spot)\n",
    "        cell_predication_spot = self.spot_head(x_spot)\n",
    "        x_local = x_local.squeeze(0)\n",
    "        cell_prediction_local = self.local_head(x_local)\n",
    "        cell_prediction_global, x_global = self.cell_transformer(x_cell)\n",
    "        cell_prediction_global = cell_prediction_global.squeeze()\n",
    "        x_global = x_global.squeeze()\n",
    "        cell_prediction_fused = self.fused_head((x_spot+x_local+x_global)/3.0)\n",
    "        cell_prediction = (cell_predication_spot + cell_prediction_local + cell_prediction_global + cell_prediction_fused) / 4.0\n",
    "        \n",
    "        return cell_prediction\n",
    "    \n",
    "    \n",
    "model = Hist2Cell(vit_depth=3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train/test split file, here we train `Hist2Cell` on other 3 donors in the humanlung cell2location dataset, and test `Hist2Cell` on the left donnor A50:\n",
    "\n",
    "There are 2 slides from donor A50 in humanlung cell2location dataset: \n",
    "- WSA_LngSP9258463\n",
    "- WSA_LngSP9258467\n",
    "\n",
    "The slides from the other 3 donors used for training are:\n",
    "- WSA_LngSP8759311\n",
    "- WSA_LngSP8759312\n",
    "- WSA_LngSP8759313\n",
    "- WSA_LngSP9258464\n",
    "- WSA_LngSP9258468\n",
    "- WSA_LngSP10193347\n",
    "- WSA_LngSP10193348\n",
    "- WSA_LngSP10193345\n",
    "- WSA_LngSP10193346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:56:33.360755800Z",
     "start_time": "2024-07-09T14:56:33.347732300Z"
    }
   },
   "outputs": [],
   "source": [
    "train_slides = open(\"../train_test_splits/humanlung_cell2location/test_leave_New.txt\").read().split('\\n')\n",
    "test_slides = open(\"../train_test_splits/humanlung_cell2location/test_leave_A50.txt\").read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the processed data for each slide as the train/test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:56:39.605049300Z",
     "start_time": "2024-07-09T14:56:34.489964400Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "\n",
    "train_graph_list = list()\n",
    "for item in train_slides:\n",
    "    train_graph_list.append(torch.load(os.path.join(\"../patch/output/pts\", item+'.pt')))\n",
    "train_dataset = Batch.from_data_list(train_graph_list)\n",
    "\n",
    "test_graph_list = list()\n",
    "for item in test_slides:\n",
    "    test_graph_list.append(torch.load(os.path.join(\"../example_data/humanlung_cell2location\", item+'.pt')))\n",
    "test_dataset = Batch.from_data_list(test_graph_list)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the `DataLoader` for train/test dataset, here are 2 important parameters:\n",
    "- `hop`: this parameter define receptive field when sampling the subgraphs with a group of center nodes for training/testing, in our paper, we use 2-hop subgraphs to achieve a banlance between computation cost and performance, generally, bigger receptive field will contain more neighboring information.\n",
    "- `subgraph_bs`: this parameter define the number of subgraphs to be sampled during training/testing, which is the `subgraph batchsize`, we use `subgraph_bs=16` on our RTX 3090 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:56:42.967289Z",
     "start_time": "2024-07-09T14:56:42.907663800Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader\n",
    "import torch_geometric\n",
    "torch_geometric.typing.WITH_PYG_LIB = False\n",
    "\n",
    "\n",
    "hop = 2\n",
    "subgraph_bs = 16\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    train_dataset,\n",
    "    num_neighbors=[-1]*hop,\n",
    "    batch_size=subgraph_bs,\n",
    "    directed=False,\n",
    "    input_nodes=None,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "test_loader = NeighborLoader(\n",
    "    test_dataset,\n",
    "    num_neighbors=[-1]*hop,\n",
    "    batch_size=subgraph_bs,\n",
    "    directed=False,\n",
    "    input_nodes=None,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the `learning rate`, `criterion`, `optimizer` and `scheduler` used for training, we use `lr=1e-4` in our study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:56:44.369202600Z",
     "start_time": "2024-07-09T14:56:44.342974100Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "params = model.parameters()\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(params, lr=lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=1e-5, last_epoch=-1, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a simple example, we train `Hist2Cell` for 5 epochs, and save the checkpoint with the best Pearson R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T14:56:18.440772Z",
     "start_time": "2024-07-09T14:55:28.790833300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Epoch: 1 \t\n",
      "lr =  0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 36\u001B[0m\n\u001B[0;32m     34\u001B[0m center_cell_label \u001B[38;5;241m=\u001B[39m cell_label[:center_num, :]\n\u001B[0;32m     35\u001B[0m center_cell_pred \u001B[38;5;241m=\u001B[39m cell_pred[:center_num, :]\n\u001B[1;32m---> 36\u001B[0m train_cell_label_array\u001B[38;5;241m.\u001B[39mappend(\u001B[43mcenter_cell_label\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[0;32m     37\u001B[0m train_cell_pred_array\u001B[38;5;241m.\u001B[39mappend(center_cell_pred\u001B[38;5;241m.\u001B[39msqueeze()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[0;32m     38\u001B[0m train_sample_num \u001B[38;5;241m=\u001B[39m train_sample_num \u001B[38;5;241m+\u001B[39m center_num\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import time\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "best_cell_abundance_all_average = 0.0\n",
    "since = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    print(\"---------------------------------------\"*4)\n",
    "    print('Epoch: {} \\t'.format(epoch + 1))\n",
    "    print('lr = ',optimizer.param_groups[0][\"lr\"])\n",
    "    \n",
    "    train_sample_num = 0\n",
    "    train_cell_pred_array = []\n",
    "    train_cell_label_array = []\n",
    "    train_cell_abundance_loss = 0\n",
    "    for graph in train_loader:\n",
    "        x = graph.x.to(device)\n",
    "        y = graph.y.to(device)\n",
    "        edge_index = graph.edge_index.to(device)\n",
    "        cell_label = y[:, 5:]\n",
    "        \n",
    "        cell_pred = model(x=x, edge_index=edge_index)\n",
    "\n",
    "        cell_loss = criterion(cell_pred, cell_label)        \n",
    "        optimizer.zero_grad()\n",
    "        cell_loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        center_num = len(graph.input_id)\n",
    "        center_cell_label = cell_label[:center_num, :]\n",
    "        center_cell_pred = cell_pred[:center_num, :]\n",
    "        train_cell_label_array.append(center_cell_label.squeeze().cpu().detach().numpy())\n",
    "        train_cell_pred_array.append(center_cell_pred.squeeze().cpu().detach().numpy())\n",
    "        train_sample_num = train_sample_num + center_num\n",
    "        train_cell_abundance_loss += cell_loss.item() * center_num\n",
    "\n",
    "    train_cell_abundance_loss = train_cell_abundance_loss / train_sample_num\n",
    "    \n",
    "    if len(train_cell_pred_array[-1].shape) == 1:\n",
    "        train_cell_pred_array[-1] = np.expand_dims(train_cell_pred_array[-1], axis=0)\n",
    "    train_cell_pred_array = np.concatenate(train_cell_pred_array)\n",
    "    if len(train_cell_label_array[-1].shape) == 1:\n",
    "        train_cell_label_array[-1] = np.expand_dims(train_cell_label_array[-1], axis=0)\n",
    "    train_cell_label_array = np.concatenate(train_cell_label_array)\n",
    "\n",
    "    train_cell_abundance_all_pearson_average = 0.0\n",
    "    for i in range(train_cell_pred_array.shape[1]):\n",
    "        r, p = pearsonr(train_cell_pred_array[:, i], train_cell_label_array[:, i])\n",
    "        train_cell_abundance_all_pearson_average = train_cell_abundance_all_pearson_average + r\n",
    "    train_cell_abundance_all_pearson_average = train_cell_abundance_all_pearson_average / train_cell_pred_array.shape[1]\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        test_sample_num = 0\n",
    "        test_cell_pred_array = []\n",
    "        test_cell_label_array = []\n",
    "        test_cell_abundance_loss = 0\n",
    "        for graph in test_loader:\n",
    "            x = graph.x.to(device)\n",
    "            y = graph.y.to(device)\n",
    "            edge_index = graph.edge_index.to(device)\n",
    "            cell_label = y[:, 5:]\n",
    "            \n",
    "            cell_pred = model(x=x, edge_index=edge_index)\n",
    "\n",
    "            cell_loss = criterion(cell_pred, cell_label)\n",
    "\n",
    "            center_num = len(graph.input_id)\n",
    "            center_cell_label = cell_label[:center_num, :]\n",
    "            center_cell_pred = cell_pred[:center_num, :]\n",
    "            \n",
    "            test_cell_label_array.append(center_cell_label.squeeze().cpu().detach().numpy())\n",
    "            test_cell_pred_array.append(center_cell_pred.squeeze().cpu().detach().numpy())\n",
    "            test_sample_num = test_sample_num + center_num\n",
    "            \n",
    "            test_cell_abundance_loss += cell_loss.item() * center_num\n",
    "            \n",
    "        test_cell_abundance_loss = test_cell_abundance_loss / test_sample_num\n",
    " \n",
    "    if len(test_cell_pred_array[-1].shape) == 1:\n",
    "        test_cell_pred_array[-1] = np.expand_dims(test_cell_pred_array[-1], axis=0)\n",
    "    test_cell_pred_array = np.concatenate(test_cell_pred_array)\n",
    "    if len(test_cell_label_array[-1].shape) == 1:\n",
    "        test_cell_label_array[-1] = np.expand_dims(test_cell_label_array[-1], axis=0)\n",
    "    test_cell_label_array = np.concatenate(test_cell_label_array)\n",
    "        \n",
    "    test_cell_abundance_all_pearson_average = 0.0\n",
    "    for i in range(test_cell_pred_array.shape[1]):\n",
    "        r, p = pearsonr(test_cell_pred_array[:, i], test_cell_label_array[:, i])\n",
    "        test_cell_abundance_all_pearson_average = test_cell_abundance_all_pearson_average + r\n",
    "    test_cell_abundance_all_pearson_average = test_cell_abundance_all_pearson_average / test_cell_pred_array.shape[1]\n",
    "\n",
    "    if test_cell_abundance_all_pearson_average > best_cell_abundance_all_average:\n",
    "        best_cell_abundance_all_average = test_cell_abundance_all_pearson_average\n",
    "        torch.save(model.state_dict(), os.path.join(\"../model_weights\", \"demo_ckpt.pth\"))\n",
    "        print(\"saving \" + \"best cell all abundance average \" + str(test_cell_abundance_all_pearson_average))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {(time_elapsed // 60):.0f}m {(time_elapsed % 60):.0f}s')\n",
    "    print(f'Epoch: {(epoch + 1)} \\tTraining Cell abundance Loss: {train_cell_abundance_loss:.6f}')\n",
    "    print(f'Epoch: {(epoch + 1)} \\tTraining Cell abundance pearson all average: {train_cell_abundance_all_pearson_average:.6f}')\n",
    "    print(f'Epoch: {(epoch + 1)} \\tTest Cell abundance Loss: {test_cell_abundance_loss:.6f}')\n",
    "    print(f'Epoch: {(epoch + 1)} \\tTest Cell abundance pearson all average: {test_cell_abundance_all_pearson_average:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0370,  0.0235,  0.0686,  ...,  0.1223, -0.0086,  0.0427],\n",
      "        [ 0.0347, -0.0085,  0.0185,  ...,  0.1063,  0.0131,  0.0358],\n",
      "        [-0.0476,  0.1360,  0.1304,  ...,  0.0942,  0.0430,  0.0147],\n",
      "        ...,\n",
      "        [-0.0139, -0.0156,  0.0503,  ...,  0.1532, -0.0064, -0.0480],\n",
      "        [-0.0058,  0.0072,  0.0547,  ...,  0.1019,  0.0237, -0.0599],\n",
      "        [-0.0116, -0.0170,  0.0524,  ...,  0.1216,  0.0048,  0.0431]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 396.00 MiB (GPU 0; 6.00 GiB total capacity; 12.06 GiB already allocated; 0 bytes free; 12.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m edge_index \u001B[38;5;241m=\u001B[39m graph\u001B[38;5;241m.\u001B[39medge_index\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      7\u001B[0m cell_label \u001B[38;5;241m=\u001B[39m y[:, \u001B[38;5;241m5\u001B[39m:]\n\u001B[1;32m----> 8\u001B[0m cell_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(cell_pred)        \n",
      "File \u001B[1;32m~\\Hist2Cell\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn[3], line 31\u001B[0m, in \u001B[0;36mHist2Cell.forward\u001B[1;34m(self, x, edge_index)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, edge_index):\n\u001B[1;32m---> 31\u001B[0m     x_spot \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresnet18\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     32\u001B[0m     x_spot \u001B[38;5;241m=\u001B[39m x_spot\u001B[38;5;241m.\u001B[39msqueeze()\n\u001B[0;32m     34\u001B[0m     x_local \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(x\u001B[38;5;241m=\u001B[39mx_spot, edge_index\u001B[38;5;241m=\u001B[39medge_index)\n",
      "File \u001B[1;32m~\\Hist2Cell\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Hist2Cell\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\Hist2Cell\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Hist2Cell\\venv\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:166\u001B[0m, in \u001B[0;36mMaxPool2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    165\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor):\n\u001B[1;32m--> 166\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_pool2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkernel_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    167\u001B[0m \u001B[43m                        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mceil_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mceil_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    168\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mreturn_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_indices\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Hist2Cell\\venv\\Lib\\site-packages\\torch\\_jit_internal.py:484\u001B[0m, in \u001B[0;36mboolean_dispatch.<locals>.fn\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    482\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m if_true(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    483\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 484\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mif_false\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Hist2Cell\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:782\u001B[0m, in \u001B[0;36m_max_pool2d\u001B[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001B[0m\n\u001B[0;32m    780\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stride \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    781\u001B[0m     stride \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mannotate(List[\u001B[38;5;28mint\u001B[39m], [])\n\u001B[1;32m--> 782\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_pool2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkernel_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mceil_mode\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 396.00 MiB (GPU 0; 6.00 GiB total capacity; 12.06 GiB already allocated; 0 bytes free; 12.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for graph in train_loader:\n",
    "        \n",
    "        x = graph.x.to(device)\n",
    "        \n",
    "        y = graph.y.to(device)\n",
    "        edge_index = graph.edge_index.to(device)\n",
    "        cell_label = y[:, 5:]\n",
    "        cell_pred = model(x=x, edge_index=edge_index)\n",
    "        print(cell_pred)        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-09T14:56:58.457603Z",
     "start_time": "2024-07-09T14:56:49.665644Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
